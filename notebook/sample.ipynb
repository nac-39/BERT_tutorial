{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## セットアップ\n",
    "\n",
    "↓こちらを元に実装しています\n",
    "\n",
    "<https://medium.com/data-and-beyond/complete-guide-to-building-bert-model-from-sratch-3e6562228891>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 研究室サーバーでuvの環境を作る場合\n",
    "# !/public/s.nanako/install_uv.sh | bash\n",
    "\n",
    "# 仮想環境のセットアップ\n",
    "# !uv sync\n",
    "# pipの場合\n",
    "# %pip install -r requirements.lock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/s.nanako/BERT_tutorial\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import requests\n",
    "\n",
    "PROJECT_ROOT = os.path.realpath(\"../\")\n",
    "!echo $PROJECT_ROOT\n",
    "\n",
    "data = requests.get(\"http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\").content\n",
    "with open(\"cornell_movie_dialogs_corpus.zip\", \"wb\") as f:\n",
    "    f.write(data)\n",
    "\n",
    "!unzip -qqo cornell_movie_dialogs_corpus.zip\n",
    "\n",
    "!rm cornell_movie_dialogs_corpus.zip\n",
    "\n",
    "if not os.path.exists(f\"{PROJECT_ROOT}/datasets/\"):\n",
    "    os.makedirs(f\"{PROJECT_ROOT}/datasets\")\n",
    "\n",
    "if not os.path.exists(f\"{PROJECT_ROOT}/datasets/movie_conversations.txt\"):\n",
    "        # ファイルの移動\n",
    "        os.rename(f\"{PROJECT_ROOT}/notebook/cornell movie-dialogs corpus/movie_conversations.txt\", \n",
    "                f\"{PROJECT_ROOT}/datasets/movie_conversations.txt\")\n",
    "        os.rename(f\"{PROJECT_ROOT}/notebook/cornell movie-dialogs corpus/movie_lines.txt\", \n",
    "                f\"{PROJECT_ROOT}/datasets/movie_lines.txt\")\n",
    "        # 後片付け\n",
    "        shutil.rmtree(f\"{PROJECT_ROOT}/notebook/cornell movie-dialogs corpus\")\n",
    "        shutil.rmtree(f\"{PROJECT_ROOT}/notebook/__MACOSX\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ダウンロードしたデータセットの形式\n",
    "\n",
    "今回は「Cornel Movie-Dialogs Corpus」を用います。\n",
    "\n",
    "[こちらより](https://arc.net/l/quote/telfmlkx)：\n",
    "\n",
    "> For our tutorial, we will be utilizing the Cornell Movie-Dialogs Corpus, a vast collection of over 220,000 conversational exchanges between more than 10,000 pairs of characters in various movies and TV shows.\n",
    "\n",
    "DeepL先生\n",
    "> このチュートリアルでは、コーネル・ムービー・ダイアログ・コーパスを利用します。コーネル・ムービー・ダイアログ・コーパスは、様々な映画やテレビ番組に登場する10,000組以上のキャラクター間の220,000以上の会話のやり取りを収録した膨大なコレクションです。\n",
    "\n",
    "続いて、各データの形式を確認していきます。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. movie_conversations.txt\n",
    "\n",
    "データ形式\n",
    "- 区切り文字`+++$+++`\n",
    "\n",
    "登場人物ID 1, 登場人物ID 2, 映画ID, 一連の会話の会話ID?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L195', 'L196', 'L197']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L198', 'L199']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L200', 'L201', 'L202', 'L203']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L204', 'L205', 'L206']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L207', 'L208']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L271', 'L272', 'L273', 'L274', 'L275']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L276', 'L277']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L280', 'L281']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L363', 'L364']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L365', 'L366']\n"
     ]
    }
   ],
   "source": [
    "!less $PROJECT_ROOT/datasets/movie_conversations.txt | head -n 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. movie_lines.txt\n",
    "データ形式\n",
    "行ID, 人物ID, 映画ID, 人物名, 会話"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\n",
      "L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\n",
      "L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.\n",
      "L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?\n",
      "L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\n",
      "L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow\n",
      "L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you're gonna need to learn how to lie.\n",
      "L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No\n",
      "L870 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I'm kidding.  You know how sometimes you just become this \"persona\"?  And you don't know how to quit?\n",
      "L869 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Like my fear of wearing pastels?\n"
     ]
    }
   ],
   "source": [
    "!less $PROJECT_ROOT/datasets/movie_lines.txt | head -n 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66:L197 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Okay... then how 'bout we try out some French cuisine.  Saturday?  Night?\n",
      "67:L196 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Not the hacking and gagging and spitting part.  Please.\n",
      "68:L195 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Well, I thought we'd start with pronunciation, if that's okay with you.\n",
      "69:L194 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\n"
     ]
    }
   ],
   "source": [
    "# ↓これが一連の会話の流れ？\n",
    "!grep -nE \"L(194|195|196|197) \" $PROJECT_ROOT/datasets/movie_lines.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データのロードの実装\n",
    "`src/bert_tutorial_data_loader.py`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## トークナイザーの実装\n",
    "\n",
    "[この章](https://arc.net/l/quote/nrfqdjbr)のメモ\n",
    "\n",
    "- BERTのトークナイザーはWordPieceトークナイザーを使う\n",
    "- WordPieceトークナイザー\n",
    "  - 一つの単語を複数のトークンに分割する可能性がある\n",
    "    - ex. surfboarding → ['surf', '##boarding', '##ing']\n",
    "    - `##`は前の単語と繋がっていたことを示すマーカー\n",
    "  - [Hugging Faceの解説](https://huggingface.co/learn/nlp-course/chapter6/6?fw=pt)\n",
    "    - かしこい…!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習を実行する\n",
    "\n",
    "main.pyがエントリーポイント"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K[00:00:00] Tokenize words                 ██████████████████ 0        /        0[00:00:00] Tokenize words                 ██████████████████ 0        /        0\n",
      "\u001b[2K[00:00:00] Count pairs                    ██████████████████ 0        /        0\n",
      "\u001b[2K[00:00:00] Compute merges                 ██████████████████ 0        /        0\n",
      "/home/s.nanako/BERT_tutorial/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2102: FutureWarning: Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.\n",
      "  warnings.warn(\n",
      "Total Parameters: 14184199\n",
      "EP_train:0:   0%|| 0/6926 [00:00<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/s.nanako/BERT_tutorial/notebook/../src/main.py\", line 30, in <module>\n",
      "    bert_trainer.train(epoch)\n",
      "  File \"/home/s.nanako/BERT_tutorial/src/bert_tutorial/train.py\", line 39, in train\n",
      "    self.iteration(epoch, self.train_data)\n",
      "  File \"/home/s.nanako/BERT_tutorial/src/bert_tutorial/train.py\", line 64, in iteration\n",
      "    next_sent_output, mask_lm_output = self.model.forward(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/s.nanako/BERT_tutorial/src/bert_tutorial/model.py\", line 112, in forward\n",
      "    x = self.bert(x, segment_label)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/s.nanako/BERT_tutorial/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/s.nanako/BERT_tutorial/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/s.nanako/BERT_tutorial/src/bert_tutorial/model.py\", line 45, in forward\n",
      "    x = self.embedding(x, segment_info)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/s.nanako/BERT_tutorial/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/s.nanako/BERT_tutorial/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/s.nanako/BERT_tutorial/src/bert_tutorial/embedding.py\", line 57, in forward\n",
      "    x = self.token(sequence) + self.position(sequence) + self.segment(segment_label)\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/s.nanako/BERT_tutorial/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/s.nanako/BERT_tutorial/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/s.nanako/BERT_tutorial/.venv/lib/python3.11/site-packages/torch/nn/modules/sparse.py\", line 190, in forward\n",
      "    return F.embedding(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/s.nanako/BERT_tutorial/.venv/lib/python3.11/site-packages/torch/nn/functional.py\", line 2551, in embedding\n",
      "    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)\n"
     ]
    }
   ],
   "source": [
    "!uv run python ../src/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
