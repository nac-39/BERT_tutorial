{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## セットアップ\n",
    "\n",
    "↓こちらを元に実装しています\n",
    "\n",
    "<https://medium.com/data-and-beyond/complete-guide-to-building-bert-model-from-sratch-3e6562228891>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !uv add  transformers datasets tokenizers\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "PROJECT_ROOT = os.path.realpath(\"../\")\n",
    "!echo $PROJECT_ROOT\n",
    "\n",
    "!wget http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
    "\n",
    "!unzip -qqo cornell_movie_dialogs_corpus.zip\n",
    "\n",
    "if not os.path.exists(f\"{PROJECT_ROOT}/notebook/cornell movie-dialogs corpus\"):\n",
    "    os.rmdir(f\"{PROJECT_ROOT}/notebook/cornell movie-dialogs corpus\")\n",
    "\n",
    "!rm cornell_movie_dialogs_corpus.zip\n",
    "\n",
    "if not os.path.exists(f\"{PROJECT_ROOT}/datasets\"):\n",
    "    os.makedirs(f\"{PROJECT_ROOT}/datasets\")\n",
    "    # ファイルの移動\n",
    "    os.rename(f\"{PROJECT_ROOT}/notebook/cornell movie-dialogs corpus/movie_conversations.txt\", \n",
    "            f\"{PROJECT_ROOT}/datasets/movie_conversations.txt\")\n",
    "    os.rename(f\"{PROJECT_ROOT}/notebook/cornell movie-dialogs corpus/movie_lines.txt\", \n",
    "            f\"{PROJECT_ROOT}/datasets/movie_lines.txt\")\n",
    "    # 後片付け\n",
    "    shutil.rmtree(f\"{PROJECT_ROOT}/notebook/cornell movie-dialogs corpus\")\n",
    "    shutil.rmtree(f\"{PROJECT_ROOT}/notebook/__MACOSX\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ダウンロードしたデータセットの形式\n",
    "\n",
    "今回は「Cornel Movie-Dialogs Corpus」を用います。\n",
    "\n",
    "[こちらより](https://arc.net/l/quote/telfmlkx)：\n",
    "\n",
    "> For our tutorial, we will be utilizing the Cornell Movie-Dialogs Corpus, a vast collection of over 220,000 conversational exchanges between more than 10,000 pairs of characters in various movies and TV shows.\n",
    "\n",
    "DeepL先生\n",
    "> このチュートリアルでは、コーネル・ムービー・ダイアログ・コーパスを利用します。コーネル・ムービー・ダイアログ・コーパスは、様々な映画やテレビ番組に登場する10,000組以上のキャラクター間の220,000以上の会話のやり取りを収録した膨大なコレクションです。\n",
    "\n",
    "続いて、各データの形式を確認していきます。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. movie_conversations.txt\n",
    "\n",
    "データ形式\n",
    "- 区切り文字`+++$+++`\n",
    "\n",
    "登場人物ID 1, 登場人物ID 2, 映画ID, 一連の会話の会話ID?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L195', 'L196', 'L197']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L198', 'L199']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L200', 'L201', 'L202', 'L203']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L204', 'L205', 'L206']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L207', 'L208']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L271', 'L272', 'L273', 'L274', 'L275']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L276', 'L277']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L280', 'L281']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L363', 'L364']\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L365', 'L366']\n"
     ]
    }
   ],
   "source": [
    "!less $PROJECT_ROOT/datasets/movie_conversations.txt | head -n 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. movie_lines.txt\n",
    "データ形式\n",
    "行ID, 人物ID, 映画ID, 人物名, 会話"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\n",
      "L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\n",
      "L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.\n",
      "L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?\n",
      "L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\n",
      "L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow\n",
      "L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you're gonna need to learn how to lie.\n",
      "L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No\n",
      "L870 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I'm kidding.  You know how sometimes you just become this \"persona\"?  And you don't know how to quit?\n",
      "L869 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Like my fear of wearing pastels?\n"
     ]
    }
   ],
   "source": [
    "!less $PROJECT_ROOT/datasets/movie_lines.txt | head -n 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66:L197 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Okay... then how 'bout we try out some French cuisine.  Saturday?  Night?\n",
      "67:L196 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Not the hacking and gagging and spitting part.  Please.\n",
      "68:L195 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Well, I thought we'd start with pronunciation, if that's okay with you.\n",
      "69:L194 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\n"
     ]
    }
   ],
   "source": [
    "# ↓これが一連の会話の流れ？\n",
    "!grep -nE \"L(194|195|196|197) \" $PROJECT_ROOT/datasets/movie_lines.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データのロードの実装\n",
    "`src/bert_tutorial_data_loader.py`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## トークナイザーの実装\n",
    "\n",
    "[この章](https://arc.net/l/quote/nrfqdjbr)のメモ\n",
    "\n",
    "- BERTのトークナイザーはWordPieceトークナイザーを使う\n",
    "- WordPieceトークナイザー\n",
    "  - 一つの単語を複数のトークンに分割する可能性がある\n",
    "    - ex. surfboarding → ['surf', '##boarding', '##ing']\n",
    "    - `##`は前の単語と繋がっていたことを示すマーカー\n",
    "  - [Hugging Faceの解説](https://huggingface.co/learn/nlp-course/chapter6/6?fw=pt)\n",
    "    - かしこい…!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
